{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Using In-Disk Data in FastEstimator\n",
    "\n",
    "In Tutorial 1, we introduced our 3 main APIs and general workflow of a deep learning task:  `Pipeline` -> `Network` -> `Estimator`. Then we used in-memory data for training. But what if the dataset size is too big to fit in memory? Say, data is in the size of ImageNet? \n",
    "\n",
    "The short answer is: user will use one more API for disk data: `RecordWriter`, such that the overall workflow becomes: `RecordWriter` -> `Pipeline` -> `Network` -> `Estimator`.\n",
    "\n",
    "In this tutorial, we are going to show you how to do in-disk data training in FastEstimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start:\n",
    "\n",
    "Two things are required regarding in-disk data : \n",
    "* Data files, obviously :)\n",
    "* A csv file that describes the data (prepare two csv files if you have a separate validation set)\n",
    "\n",
    "In csv file, the rows of csv represent different examples and columns represent different features within example. For example, for a classification task, a csv may look like:\n",
    "\n",
    "| image  | label  |\n",
    "|---|---|\n",
    "|/data/image1.png   | 0  |\n",
    "|/data/image2.png   |  1 |\n",
    "|/data/image3.png | 0  |\n",
    "|... | .  |\n",
    "\n",
    "The csv of a multi-mask segmentation task may look like:\n",
    "\n",
    "| img  | msk1  | msk2  |\n",
    "|---|---|---|\n",
    "|/data/image1.png   | /maska/mask1.png  |/maskb/mask1.png|\n",
    "|/data/image2.png   |  /maska/mask2.png |/maskb/mask2.png|\n",
    "|/data/image3.png | /maska/mask3.png  |/maskb/mask3.png|\n",
    "|... | ...  |...|\n",
    "\n",
    "\n",
    "Please keep in mind that, there is no restriction on the data folder structures, number of features or name of features. \n",
    "\n",
    "Now, let's generate some in-disk data for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing image data to /var/folders/5g/d_ny7h211cj3zqkzrtq01s480000gn/T/.fe/Mnist/image\n",
      "training csv path is /var/folders/5g/d_ny7h211cj3zqkzrtq01s480000gn/T/.fe/Mnist/train.csv\n",
      "evaluation csv path is /var/folders/5g/d_ny7h211cj3zqkzrtq01s480000gn/T/.fe/Mnist/eval.csv\n",
      "mnist image path is /var/folders/5g/d_ny7h211cj3zqkzrtq01s480000gn/T/.fe/Mnist/image\n"
     ]
    }
   ],
   "source": [
    "from fastestimator.dataset.mnist import load_data\n",
    "\n",
    "train_csv, eval_csv, image_path = load_data()\n",
    "print(\"training csv path is {}\".format(train_csv))\n",
    "print(\"evaluation csv path is {}\".format(eval_csv))\n",
    "print(\"mnist image path is {}\".format(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        Unnamed: 0                x  y\n",
      "0               0      train_0.png  5\n",
      "1               1      train_1.png  0\n",
      "2               2      train_2.png  4\n",
      "3               3      train_3.png  1\n",
      "4               4      train_4.png  9\n",
      "5               5      train_5.png  2\n",
      "6               6      train_6.png  1\n",
      "7               7      train_7.png  3\n",
      "8               8      train_8.png  1\n",
      "9               9      train_9.png  4\n",
      "10             10     train_10.png  3\n",
      "11             11     train_11.png  5\n",
      "12             12     train_12.png  3\n",
      "13             13     train_13.png  6\n",
      "14             14     train_14.png  1\n",
      "15             15     train_15.png  7\n",
      "16             16     train_16.png  2\n",
      "17             17     train_17.png  8\n",
      "18             18     train_18.png  6\n",
      "19             19     train_19.png  9\n",
      "20             20     train_20.png  4\n",
      "21             21     train_21.png  0\n",
      "22             22     train_22.png  9\n",
      "23             23     train_23.png  1\n",
      "24             24     train_24.png  1\n",
      "25             25     train_25.png  2\n",
      "26             26     train_26.png  4\n",
      "27             27     train_27.png  3\n",
      "28             28     train_28.png  2\n",
      "29             29     train_29.png  7\n",
      "...           ...              ... ..\n",
      "59970       59970  train_59970.png  2\n",
      "59971       59971  train_59971.png  2\n",
      "59972       59972  train_59972.png  0\n",
      "59973       59973  train_59973.png  9\n",
      "59974       59974  train_59974.png  2\n",
      "59975       59975  train_59975.png  4\n",
      "59976       59976  train_59976.png  6\n",
      "59977       59977  train_59977.png  7\n",
      "59978       59978  train_59978.png  3\n",
      "59979       59979  train_59979.png  1\n",
      "59980       59980  train_59980.png  3\n",
      "59981       59981  train_59981.png  6\n",
      "59982       59982  train_59982.png  6\n",
      "59983       59983  train_59983.png  2\n",
      "59984       59984  train_59984.png  1\n",
      "59985       59985  train_59985.png  2\n",
      "59986       59986  train_59986.png  6\n",
      "59987       59987  train_59987.png  0\n",
      "59988       59988  train_59988.png  7\n",
      "59989       59989  train_59989.png  8\n",
      "59990       59990  train_59990.png  9\n",
      "59991       59991  train_59991.png  2\n",
      "59992       59992  train_59992.png  9\n",
      "59993       59993  train_59993.png  5\n",
      "59994       59994  train_59994.png  1\n",
      "59995       59995  train_59995.png  8\n",
      "59996       59996  train_59996.png  3\n",
      "59997       59997  train_59997.png  5\n",
      "59998       59998  train_59998.png  6\n",
      "59999       59999  train_59999.png  8\n",
      "\n",
      "[60000 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "print(df_train.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: RecordWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
