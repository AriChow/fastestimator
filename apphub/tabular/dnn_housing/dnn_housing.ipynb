{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston housing price predictor (regression) using DNN\n",
    "\n",
    "## Step 1: Prepare training and evaluation dataset, create FastEstimator Pipeline\n",
    "\n",
    "Pipeline can take both data in memory and data in disk. In this example, we are going to use data in memory by loading data with tf.keras.datasets.boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is (404, 13)\n",
      "train value shape is (404,)\n",
      "eval shape is (102, 13)\n",
      "eval value shape is (102,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.boston_housing.load_data()\n",
    "print(\"train shape is {}\".format(x_train.shape))\n",
    "print(\"train value shape is {}\".format(y_train.shape))\n",
    "print(\"eval shape is {}\".format(x_eval.shape))\n",
    "print(\"eval value shape is {}\".format(y_eval.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to scale the inputs to the neural network. This is done by using a StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_eval = scaler.transform(x_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For in-memory data in Pipeline, the data format should be a nested dictionary like: {\"mode1\": {\"feature1\": numpy_array, \"feature2\": numpy_array, ...}, ...}. Each mode can be either train or eval, in our case, we have both train and eval. feature is the feature name, in our case, we have x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"train\": {\n",
    "            \"x\": x_train, \"y\": y_train\n",
    "        },\n",
    "        \"eval\": {\n",
    "            \"x\": x_eval, \"y\": y_eval\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastestimator as fe\n",
    "\n",
    "pipeline = fe.Pipeline(batch_size=32, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare model, create FastEstimator Network\n",
    "\n",
    "First, we have to define the network architecture in tf.keras.Model or tf.keras.Sequential. After defining the architecture, users are expected to feed the architecture definition and its associated model name, optimizer and loss name (default to be 'loss') to FEModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from fastestimator.network.model import FEModel\n",
    "\n",
    "def create_dnn():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(64, activation=\"relu\", input_shape=(13,)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = FEModel(model_def=create_dnn, model_name=\"dnn\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define the Network: given with a batch data with key x and y, we have to work our way to loss with series of operators. ModelOp is an operator that contains a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.network.model import ModelOp\n",
    "from fastestimator.network.loss import MeanSquaredError\n",
    "\n",
    "network = fe.Network(\n",
    "    ops=[ModelOp(inputs=\"x\", model=model, outputs=\"y_pred\"), MeanSquaredError(y_true=\"y\", y_pred=\"y_pred\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure training, create Estimator\n",
    "\n",
    "During the training loop, we want to: 1) measure lowest loss for data data 2) save the model with lowest valdiation loss. Trace class is used for anything related to training loop, we will need to import the ModelSaver trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from fastestimator.estimator.trace import ModelSaver\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "traces = [ModelSaver(model_name=\"dnn\", save_dir=model_dir, save_best=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the Estimator and specify the training configuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(network=network, pipeline=pipeline, epochs=50, traces=traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 0; dnn_lr: 0.001; \n",
      "FastEstimator-Train: step: 0; loss: 667.34644; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 12; epoch: 0; loss: 533.3779; since_best_loss: 0; min_loss: 533.3779; \n",
      "FastEstimator-Eval: step: 24; epoch: 1; loss: 568.65344; since_best_loss: 1; min_loss: 533.3779; \n",
      "FastEstimator-Eval: step: 36; epoch: 2; loss: 554.3767; since_best_loss: 2; min_loss: 533.3779; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 48; epoch: 3; loss: 492.90234; since_best_loss: 0; min_loss: 492.90234; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 60; epoch: 4; loss: 448.32336; since_best_loss: 0; min_loss: 448.32336; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 72; epoch: 5; loss: 364.52982; since_best_loss: 0; min_loss: 364.52982; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 84; epoch: 6; loss: 280.4054; since_best_loss: 0; min_loss: 280.4054; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 96; epoch: 7; loss: 221.81287; since_best_loss: 0; min_loss: 221.81287; \n",
      "FastEstimator-Train: step: 100; loss: 179.40372; examples/sec: 15470.51; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 108; epoch: 8; loss: 158.10905; since_best_loss: 0; min_loss: 158.10905; \n",
      "FastEstimator-Eval: step: 120; epoch: 9; loss: 167.22707; since_best_loss: 1; min_loss: 158.10905; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 132; epoch: 10; loss: 134.05768; since_best_loss: 0; min_loss: 134.05768; \n",
      "FastEstimator-Eval: step: 144; epoch: 11; loss: 144.704; since_best_loss: 1; min_loss: 134.05768; \n",
      "FastEstimator-Eval: step: 156; epoch: 12; loss: 168.42738; since_best_loss: 2; min_loss: 134.05768; \n",
      "FastEstimator-Eval: step: 168; epoch: 13; loss: 140.99545; since_best_loss: 3; min_loss: 134.05768; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 180; epoch: 14; loss: 132.6551; since_best_loss: 0; min_loss: 132.6551; \n",
      "FastEstimator-Eval: step: 192; epoch: 15; loss: 169.61348; since_best_loss: 1; min_loss: 132.6551; \n",
      "FastEstimator-Train: step: 200; loss: 235.34052; examples/sec: 15429.82; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 204; epoch: 16; loss: 116.086754; since_best_loss: 0; min_loss: 116.086754; \n",
      "FastEstimator-Eval: step: 216; epoch: 17; loss: 129.89822; since_best_loss: 1; min_loss: 116.086754; \n",
      "FastEstimator-Eval: step: 228; epoch: 18; loss: 145.96028; since_best_loss: 2; min_loss: 116.086754; \n",
      "FastEstimator-Eval: step: 240; epoch: 19; loss: 121.20874; since_best_loss: 3; min_loss: 116.086754; \n",
      "FastEstimator-Eval: step: 252; epoch: 20; loss: 132.74513; since_best_loss: 4; min_loss: 116.086754; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 264; epoch: 21; loss: 111.37405; since_best_loss: 0; min_loss: 111.37405; \n",
      "FastEstimator-Eval: step: 276; epoch: 22; loss: 130.03984; since_best_loss: 1; min_loss: 111.37405; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 288; epoch: 23; loss: 111.36023; since_best_loss: 0; min_loss: 111.36023; \n",
      "FastEstimator-Eval: step: 300; epoch: 24; loss: 125.954765; since_best_loss: 1; min_loss: 111.36023; \n",
      "FastEstimator-Train: step: 300; loss: 88.36313; examples/sec: 15400.54; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 312; epoch: 25; loss: 98.52128; since_best_loss: 0; min_loss: 98.52128; \n",
      "FastEstimator-Eval: step: 324; epoch: 26; loss: 147.05247; since_best_loss: 1; min_loss: 98.52128; \n",
      "FastEstimator-Eval: step: 336; epoch: 27; loss: 106.8653; since_best_loss: 2; min_loss: 98.52128; \n",
      "FastEstimator-Eval: step: 348; epoch: 28; loss: 141.3849; since_best_loss: 3; min_loss: 98.52128; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 360; epoch: 29; loss: 86.96637; since_best_loss: 0; min_loss: 86.96637; \n",
      "FastEstimator-Eval: step: 372; epoch: 30; loss: 127.47927; since_best_loss: 1; min_loss: 86.96637; \n",
      "FastEstimator-Eval: step: 384; epoch: 31; loss: 136.50368; since_best_loss: 2; min_loss: 86.96637; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmp3yb752cp/dnn_best_loss.h5\n",
      "FastEstimator-Eval: step: 396; epoch: 32; loss: 80.8536; since_best_loss: 0; min_loss: 80.8536; \n",
      "FastEstimator-Train: step: 400; loss: 162.81401; examples/sec: 15548.77; \n",
      "FastEstimator-Eval: step: 408; epoch: 33; loss: 143.59637; since_best_loss: 1; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 420; epoch: 34; loss: 91.310844; since_best_loss: 2; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 432; epoch: 35; loss: 121.72062; since_best_loss: 3; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 444; epoch: 36; loss: 112.33902; since_best_loss: 4; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 456; epoch: 37; loss: 114.89374; since_best_loss: 5; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 468; epoch: 38; loss: 118.930664; since_best_loss: 6; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 480; epoch: 39; loss: 113.44569; since_best_loss: 7; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 492; epoch: 40; loss: 116.649956; since_best_loss: 8; min_loss: 80.8536; \n",
      "FastEstimator-Train: step: 500; loss: 211.98346; examples/sec: 15681.11; \n",
      "FastEstimator-Eval: step: 504; epoch: 41; loss: 115.87998; since_best_loss: 9; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 516; epoch: 42; loss: 109.517235; since_best_loss: 10; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 528; epoch: 43; loss: 119.50488; since_best_loss: 11; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 540; epoch: 44; loss: 110.73612; since_best_loss: 12; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 552; epoch: 45; loss: 114.30173; since_best_loss: 13; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 564; epoch: 46; loss: 104.621025; since_best_loss: 14; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 576; epoch: 47; loss: 101.72397; since_best_loss: 15; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 588; epoch: 48; loss: 129.98547; since_best_loss: 16; min_loss: 80.8536; \n",
      "FastEstimator-Eval: step: 600; epoch: 49; loss: 103.951485; since_best_loss: 17; min_loss: 80.8536; \n",
      "FastEstimator-Finish: step: 600; total_time: 2.36 sec; dnn_lr: 0.001; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing\n",
    "\n",
    "After training, the model is saved to a temporary folder. we can load the model from file and do inferencing on a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join(model_dir, 'dnn_best_loss.h5')\n",
    "trained_model = tf.keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly get one sample from validation set and compare the predicted value with model's prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sample idx 94, ground truth: 35.1\n",
      "model predicted value is [[19.924725]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "selected_idx = np.random.randint(0, high=101)\n",
    "print(\"test sample idx {}, ground truth: {}\".format(selected_idx, y_eval[selected_idx]))\n",
    "\n",
    "test_sample = np.expand_dims(x_eval[selected_idx], axis=0)\n",
    "\n",
    "predicted_value = trained_model.predict(test_sample)\n",
    "print(\"model predicted value is {}\".format(predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FE",
   "language": "python",
   "name": "fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
